{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyORTOmzW3Z8Gy/e0sZvqpGA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, datasets, transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "z8pTNX_i36tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#트레이닝 데이터 준비\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\" 'data.zip' 파일을 업로드하세요.\")\n",
        "uploaded = files.upload()\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "extract_path = \"/content\"\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\" '{zip_filename}' 압축 해제 완료\")\n",
        "print(\"/content/data 안의 클래스 폴더:\")\n",
        "!ls /content/data"
      ],
      "metadata": {
        "id": "9bZBCtvzBNmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 증강\n",
        "\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "augment = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=1.0),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.95, 1.05)),\n",
        "])\n",
        "\n",
        "data_root = \"/content/data\"\n",
        "\n",
        "image_extensions = ['.jpg', '.jpeg', '.png']\n",
        "\n",
        "for class_name in os.listdir(data_root):\n",
        "    class_path = os.path.join(data_root, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"클래스 '{class_name}' 증강 중...\")\n",
        "\n",
        "    img_files = [f for f in os.listdir(class_path) if os.path.splitext(f)[-1].lower() in image_extensions]\n",
        "\n",
        "    for img_name in tqdm(img_files):\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            augmented = augment(img)\n",
        "\n",
        "            name, ext = os.path.splitext(img_name)\n",
        "            new_name = f\"{name}_aug1{ext}\"\n",
        "            save_path = os.path.join(class_path, new_name)\n",
        "            augmented.save(save_path)\n",
        "        except Exception as e:\n",
        "            print(f\"이미지 오류: {img_name}, {e}\")"
      ],
      "metadata": {
        "id": "Jv8Ig2OOsu4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRnO0Jlsj5fV"
      },
      "outputs": [],
      "source": [
        "#모델 트레이닝\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "def train_call_duck_classifier_full(data_dir=\"/content/data\", num_epochs=15, batch_size=8):\n",
        "    # 전처리 정의\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    class CleanImageFolder(datasets.ImageFolder):\n",
        "        def find_classes(self, directory):\n",
        "            classes = [d.name for d in os.scandir(directory) if d.is_dir() and d.name != '.ipynb_checkpoints']\n",
        "            classes.sort()\n",
        "            class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "            return classes, class_to_idx\n",
        "\n",
        "    dataset = CleanImageFolder(data_dir, transform=transform)\n",
        "    class_names = dataset.classes\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = models.mobilenet_v3_large(pretrained=True)\n",
        "    model.classifier[3] = nn.Linear(1280, num_classes)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"[Epoch {epoch+1}] Loss: {total_loss:.4f}\")\n",
        "\n",
        "    # 모델 저장\n",
        "    torch.save(model.state_dict(), \"/content/mobilenetv3_call_duck.pt\")\n",
        "    print(\"훈련 완료 및 모델 저장됨\")\n",
        "\n",
        "    return model, class_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 트레이닝 실행\n",
        "model, class_names = train_call_duck_classifier_full()"
      ],
      "metadata": {
        "id": "GTc_NrjJ4nrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 분류\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "model = models.mobilenet_v3_large(pretrained=False)\n",
        "model.classifier[3] = nn.Linear(1280, 5)\n",
        "model.load_state_dict(torch.load(\"/content/mobilenetv3_call_duck.pt\", map_location='cpu'))\n",
        "model.eval()\n",
        "\n",
        "class_names = ['call_duck', 'goose', 'mallard', 'other', 'pekin']\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std =[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "input_tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    pred = torch.argmax(output, dim=1).item()\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Predicted: {class_names[pred]}\")\n",
        "plt.show()\n",
        "print(f\"이 이미지는 '{class_names[pred]}'로 분류되었습니다.\")"
      ],
      "metadata": {
        "id": "304OneNKVGgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#가중치 로드\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "model = models.mobilenet_v3_large(pretrained=False)\n",
        "model.classifier[3] = nn.Linear(1280, 5)  # 콜덕 / 기타\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/mobilenetv3_call_duck.pt\", map_location='cpu'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "eDP3xVcL9BvM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grad-CAM 시각화\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def show_gradcam(image_path, model, class_names, target_layer='features.16'):\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    features, gradients = [], []\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        features.append(output)\n",
        "    def backward_hook(module, grad_input, grad_output):\n",
        "        gradients.append(grad_output[0])\n",
        "\n",
        "    layer = dict([*model.named_modules()])[target_layer]\n",
        "    fh = layer.register_forward_hook(forward_hook)\n",
        "    bh = layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    output = model(input_tensor)\n",
        "    pred_class = output.argmax(dim=1).item()\n",
        "    pred_name = class_names[pred_class]\n",
        "\n",
        "    model.zero_grad()\n",
        "    output[0, pred_class].backward()\n",
        "\n",
        "    pooled_grad = torch.mean(gradients[0], dim=(0, 2, 3))\n",
        "    fmap = features[0][0]\n",
        "    cam = torch.zeros(fmap.shape[1:], dtype=torch.float32).to(device)\n",
        "    for i in range(len(pooled_grad)):\n",
        "        cam += pooled_grad[i] * fmap[i, :, :]\n",
        "\n",
        "    cam = cam.cpu().detach().numpy()\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cam / cam.max() if cam.max() != 0 else cam\n",
        "\n",
        "    cam_resized = cv2.resize(cam, image.size)\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "    overlay = (np.array(image) * 0.5 + heatmap * 0.5).astype(np.uint8)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(overlay)\n",
        "    plt.title(f\"Grad-CAM (Predicted: {pred_name})\", fontsize=14)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    fh.remove()\n",
        "    bh.remove()\n",
        "    print(f\"Result: {pred_name}\")\n",
        "\n",
        "show_gradcam(image_path, model, class_names)"
      ],
      "metadata": {
        "id": "vYsKjITT8GUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가용 데이터 준비\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"'eval_data.zip' 파일을 업로드하세요.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "extract_path = \"/content\"\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"'{zip_filename}' 압축 해제 완료\")\n",
        "\n",
        "eval_path = os.path.join(extract_path, \"eval_data\")\n",
        "print(\"\\n /content/eval_data 안의 클래스 폴더:\")\n",
        "!ls /content/eval_data"
      ],
      "metadata": {
        "id": "l-Szaf-s4jlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#정확도 평가\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 데이터 경로: 평가용 폴더 (클래스별로 하위 폴더 구분)\n",
        "eval_dir = \"/content/eval_data\"  # 예: eval_data/call_duck/, eval_data/goose/ ...\n",
        "\n",
        "class_names = sorted([d for d in os.listdir(eval_dir) if os.path.isdir(os.path.join(eval_dir, d))])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "eval_dataset = datasets.ImageFolder(eval_dir, transform=transform)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "model = models.mobilenet_v3_large(pretrained=False)\n",
        "model.classifier[3] = nn.Linear(1280, len(class_names))\n",
        "model.load_state_dict(torch.load(\"/content/mobilenetv3_call_duck.pt\", map_location='cpu'))\n",
        "model.eval()\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in eval_loader:\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.tolist())\n",
        "        y_pred.extend(preds.tolist())\n",
        "\n",
        "print(\"정확도:\", np.mean(np.array(y_true) == np.array(y_pred)) * 100, \"%\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ARNooMPh4xyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "\n",
        "model = models.mobilenet_v3_large(pretrained=True)\n",
        "model.classifier[3] = nn.Linear(1280, 5)\n",
        "model.load_state_dict(torch.load(\"mobilenetv3_call_duck.pt\"))\n",
        "model.eval()\n",
        "\n",
        "scripted = torch.jit.script(model)\n",
        "\n",
        "optimized = optimize_for_mobile(scripted)\n",
        "\n",
        "optimized._save_for_lite_interpreter(\"call_duck_classifier.ptl\")\n"
      ],
      "metadata": {
        "id": "ceN9roxvXlpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}